# Perceptor-Remote Implementation Notes

**Date Started**: 2025-11-24
**Phase**: 1 - Core Streaming

---

## Implementation Log

### Directory Setup
- ‚úÖ Created `/web/perceptor-remote/` directory
- ‚úÖ Created implementation notes file

### Next Steps
- [ ] Create `index.html` with inline CSS
- [ ] Create `app.js` with Phase 1 functionality

---

## Design Notes

### Architecture
- Single HTML file with inline CSS (keep it simple)
- One JavaScript module (app.js)
- Console-first approach (UI later)
- Dynamic DB settings for all configuration

### Key Features (Phase 1)
- Hardware: Webcam + Mic initialization
- DB: Load active audio/visual prompts
- Gemini: WebSocket connection with Live API
- Audio: Continuous PCM streaming (configurable interval)
- Visual: Frame capture every 4s
- Output: Console logging of percepts

---

## Implementation Progress

### Bug Fix: Sample Rate Confusion (2025-11-24)
- ‚ùå **Bug**: Used `sample_rate` from DB (512) as AudioContext sample rate
- ‚úÖ **Fix**: AudioContext always uses 16000Hz (Gemini Live API requirement)
- ‚úÖ **Clarification**: `sample_rate` field in DB is the ScriptProcessor buffer size
- ‚úÖ **Updated**: All references to use correct naming
- ‚úÖ **Fixed UI**: Updated audio-percept editor label to "Buffer Size (samples)"
- ‚úÖ **Added Comments**: Clarified in code that sample_rate is buffer size

### Bug Fix: Blob Message Handling (2025-11-24)
- ‚ùå **Bug**: Gemini sends Blob messages, code tried to parse directly as JSON
- ‚úÖ **Fix**: Added Blob detection and async text conversion before parsing
- ‚úÖ **Pattern**: Same approach used in audio-percept and visual-percept editors
- ‚úÖ **Error**: "Unexpected token 'o', '[object Blob]' is not valid JSON" - RESOLVED

**Technical Details:**
- AudioContext sample rate: **16000Hz** (fixed, required by Gemini)
- ScriptProcessor buffer: **512/1024/4096/8192** (from DB `sample_rate` field)
- DB field name kept as `sample_rate` for backward compatibility
- UI now correctly labeled as "Buffer Size (samples)"
- WebSocket messages: Handle both Blob and text formats

### HTML & CSS (Completed)
- ‚úÖ Created `index.html` with inline CSS
- ‚úÖ Simple, dark-themed UI
- ‚úÖ Video preview section
- ‚úÖ Info panel showing loaded prompts and settings
- ‚úÖ Status bar (Gemini + Streaming)
- ‚úÖ Start/Stop controls
- ‚úÖ Console output area with colored log entries

### App.js - Core Logic (Completed)
- ‚úÖ **State Management**: Single state object with all necessary fields
- ‚úÖ **Initialization Flow**:
  - Load active audio/visual prompts from DB
  - Extract sample rate, buffer size, packet interval dynamically
  - Initialize webcam (640x480)
  - Initialize microphone with DB sample rate
  - Setup audio processing (PCM conversion)
- ‚úÖ **Audio Processing**:
  - AudioContext with dynamic sample rate
  - ScriptProcessorNode with dynamic buffer size
  - Float32 ‚Üí Int16 PCM conversion
  - Buffer accumulation during streaming
- ‚úÖ **Gemini Live Connection**:
  - Ephemeral token fetch
  - WebSocket URL construction (handles ephemeral vs API key)
  - Setup message with audio prompt + generation config
  - Event handlers (open, message, error, close)
- ‚úÖ **Audio Streaming Loop**:
  - Dynamic packet interval from DB
  - MIN/MAX samples calculated from sample rate
  - Little-endian PCM encoding
  - Base64 conversion
  - Sends via `realtimeInput` format
- ‚úÖ **Visual Streaming Loop**:
  - Fixed 4-second interval
  - Canvas-based frame capture
  - JPEG encoding (0.8 quality)
  - Sends via `clientContent` format with visual user prompt
- ‚úÖ **Response Handler**:
  - Setup complete detection
  - Text accumulation from streaming parts
  - Turn complete detection
  - JSON sanitization (removes markdown code fences)
  - Schema discrimination (audio vs visual)
  - Console logging by type
- ‚úÖ **Start/Stop Controls**:
  - Start: Connect Gemini ‚Üí Wait for setup ‚Üí Start loops
  - Stop: Clear intervals ‚Üí Close WebSocket ‚Üí Clear buffer
  - UI state updates
- ‚úÖ **UI Updates**:
  - Status indicators (Gemini, Streaming)
  - Button enable/disable logic
  - Info panel population
  - Console logging with timestamps and color-coding

### Code Quality
- ‚úÖ Well-organized with 10 clear sections
- ‚úÖ All DB settings used dynamically
- ‚úÖ Error handling throughout
- ‚úÖ Console logging for debugging
- ‚úÖ Follows functional programming style
- ‚úÖ ~550 lines, clean and maintainable

### Server Integration (Completed)
- ‚úÖ Added route to `server.js`: `/perceptor-remote`
- ‚úÖ Serves static files from `web/perceptor-remote/`
- ‚úÖ No auth required (user-facing app)
- ‚úÖ All required APIs already exist:
  - `/api/audio-prompts/active`
  - `/api/visual-prompts/active`
  - `/api/gemini/token`

---

## Testing Readiness

### Ready to Test
The Phase 1 implementation is **complete and ready for testing**!

### How to Test
1. Start server: `npm start` (or `npm run client:local`)
2. Open browser: `http://localhost:3001/perceptor-remote`
3. Click START button
4. Verify:
   - ‚úÖ Video preview shows webcam
   - ‚úÖ Gemini status shows connected
   - ‚úÖ Console shows audio packets being sent
   - ‚úÖ Console shows visual frames being sent
   - ‚úÖ Audio percepts appear (speak into microphone)
   - ‚úÖ Visual percepts appear (wave at camera)
5. Click STOP button
6. Verify streaming stops cleanly

### Expected Behavior
- **Initialization**: Loads prompts, shows settings, initializes hardware
- **Gemini Connection**: Connects, sends setup, shows "Connected"
- **Audio Streaming**: Sends PCM packets every 500ms (default)
- **Visual Streaming**: Sends frames every 4s
- **Audio Percepts**: Console logs with transcript, analysis, tone, emoji, sentiment, confidence, sigilPhrase, sigilDrawCalls
- **Visual Percepts**: Console logs with description, sigilPhrase, drawCalls
- **Stop**: Cleanly stops all intervals and closes WebSocket

---

## Known Limitations (Phase 1)

### What's NOT Included (Yet)
- ‚ùå Cognizer integration (Phase 2)
- ‚ùå Mind moment reception
- ‚ùå Sigil visualization
- ‚ùå Percept forwarding to cognizer
- ‚ùå Session management

### Phase 1 Scope
This implementation is **console-first** for development and testing:
- Logs percepts to browser console
- Logs percepts to on-page console area
- No fancy UI (just status indicators)
- No percept forwarding (just Gemini ‚Üí Console)

---

## Next Steps (Phase 2)

When Phase 1 is tested and working:

1. Add Socket.io client for Cognizer connection
2. Implement `connectToCognizer()` function
3. Implement percept transformation (visual schema fix)
4. Forward percepts to Cognizer WebSocket
5. Listen for mind moments
6. Display mind moments in UI
7. Test full pipeline: Gemini ‚Üí Perceptor ‚Üí Cognizer

---

## File Manifest

```
/web/perceptor-remote/
  index.html              ~195 lines (HTML + inline CSS)
  app.js                  ~550 lines (all Phase 1 logic)
  implementation-notes.md ~200 lines (this file)
```

---

## Success Metrics

### Phase 1 Complete ‚úÖ
- [x] Directory created
- [x] HTML with inline CSS
- [x] App.js with 10 sections
- [x] Dynamic DB settings
- [x] Hardware initialization
- [x] Gemini Live connection
- [x] Audio streaming (configurable)
- [x] Visual streaming (4s interval)
- [x] Response parsing
- [x] Console logging
- [x] Start/Stop controls
- [x] Server route added
- [x] Implementation notes

### Ready for User Testing ‚úÖ

---

**Implementation Status**: Phase 1 COMPLETE (with Dual-WebSocket Refactor) üéâ

**Next Action**: User testing and verification

**Date Completed**: 2025-11-24

---

## Major Refactor: Dual WebSocket Architecture (2025-11-24)

### Problem
Initial implementation used a **single WebSocket** with interleaved messages:
- Audio prompt in setup (system instruction)
- Visual frames sent with user prompt
- Both responses came back on same channel
- Schema discrimination was fragile and error-prone

### Issues Encountered
1. **Schema Collision**: Audio prompt started generating `sigilPhrase`, breaking visual detection
2. **Silence Spam**: Audio percepts logged for silence, cluttering console
3. **JSON Parse Errors**: Occasional partial responses
4. **Complex Discrimination**: Required checking multiple fields to determine percept type

### Solution: Dual WebSocket Pattern
Refactored to use **TWO separate Gemini Live connections**:

```
Audio WebSocket:                    Visual WebSocket:
‚îú‚îÄ Setup with audio prompt         ‚îú‚îÄ Setup with visual prompt
‚îú‚îÄ Audio generation config          ‚îú‚îÄ Visual generation config
‚îú‚îÄ Continuous PCM streaming         ‚îú‚îÄ Periodic frames (4s)
‚îî‚îÄ Audio percept responses          ‚îî‚îÄ Visual percept responses
```

### Implementation Changes

#### 1. State Management
```javascript
// OLD (single WebSocket)
geminiWs: null
geminiConnected: false
setupComplete: false
responseBuffer: ''

// NEW (dual WebSocket)
audioWs: null
audioConnected: false
audioSetupComplete: false
audioResponseBuffer: ''

visualWs: null
visualConnected: false
visualSetupComplete: false
visualResponseBuffer: ''
```

#### 2. Connection Functions
- **`startAudioSession()`**: Audio WebSocket with audio prompt
- **`startVisualSession()`**: Visual WebSocket with visual prompt
- Both started in parallel via `Promise.all()`

#### 3. Response Handlers
- **`handleAudioResponse(message)`**: 
  - No schema checking needed (knows it's audio)
  - Filters silence (`action.includes('silence')`)
  - Logs valid audio percepts
  
- **`handleVisualResponse(message)`**: 
  - No schema checking needed (knows it's visual)
  - Logs all visual percepts

#### 4. Streaming Functions
- **`startAudioStreaming()`**: Sends to `audioWs`
- **`startVisualStreaming()`**: Sends to `visualWs`
- Each checks its own `setupComplete` flag

#### 5. Control Flow
```javascript
start() {
  await Promise.all([
    startAudioSession(),
    startVisualSession()
  ]);
  await waitForSetup(); // Waits for BOTH
  startAudioStreaming();
  startVisualStreaming();
}

stop() {
  clearInterval(audioInterval);
  clearInterval(visualInterval);
  audioWs.close();
  visualWs.close();
}
```

#### 6. UI Updates
- Shows both channel statuses: `üé§` (audio) and `üëÅÔ∏è` (visual)
- Connection progress shows which channels are ready
- Setup timeout reports which channel(s) failed

### Benefits

1. **‚úÖ No Schema Collision**: Each channel has its own response format
2. **‚úÖ Cleaner Code**: No discrimination logic needed
3. **‚úÖ Silence Filtering**: Built into audio handler
4. **‚úÖ Independent Failure**: One channel can fail without affecting the other
5. **‚úÖ Clearer Debugging**: Each channel logs independently
6. **‚úÖ Better Error Handling**: Per-channel error tracking

### Trade-offs

1. **Two Ephemeral Tokens**: Requires two API calls (negligible cost)
2. **Two WebSocket Connections**: More network overhead (acceptable for real-time)
3. **Slightly More Complex State**: But cleaner overall logic

### Code Quality
- ‚úÖ Well-organized sections maintained
- ‚úÖ No linter errors
- ‚úÖ Clear separation of concerns
- ‚úÖ Follows existing patterns from prompt editors

### Testing Notes
The refactored implementation should:
- ‚úÖ Connect both channels in parallel
- ‚úÖ Show dual status in UI
- ‚úÖ Filter silence from audio
- ‚úÖ Log visual percepts separately
- ‚úÖ Handle independent failures gracefully

---

**Final Status**: Phase 1 COMPLETE with production-ready dual-WebSocket architecture

**Ready for**: User testing, integration with Cognizer (Phase 2)

