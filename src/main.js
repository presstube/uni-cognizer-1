/**
 * MVP Cognizer-1: Main Cognitive Loop
 * 
 * Architecture:
 *   Mock Percepts â†’ Cognitive Loop (5sec) â†’ GPT-4o â†’ Emotional Plan â†’ Console
 * 
 * This is the robot's heartbeat - a continuous cycle of:
 *   1. Gathering percepts
 *   2. Processing them into emotional understanding
 *   3. Expressing that understanding
 */

import 'dotenv/config';
import { generateVisualPercept, generateAudioPercept, aggregatePercepts } from './mock-percepts.js';
import { generateEmotionalPlan } from './cognitive-core.js';

// Configuration
const COGNITIVE_CYCLE_MS = parseInt(process.env.COGNITIVE_CYCLE_MS) || 5000;
const VISUAL_PERCEPT_INTERVAL_MS = parseInt(process.env.VISUAL_PERCEPT_INTERVAL_MS) || 2000;
const AUDIO_PERCEPT_INTERVAL_MS = parseInt(process.env.AUDIO_PERCEPT_INTERVAL_MS) || 3000;

// State (in-memory only for MVP)
const perceptBuffer = [];
let previousEmotionalState = null;
let cycleCount = 0;

/**
 * Format emotional plan for console display
 */
function displayEmotionalPlan(plan, cycleNum) {
  console.log(`\n${'â•'.repeat(60)}`);
  console.log(`ðŸ§  Cognitive Cycle #${cycleNum}`);
  console.log(`${'â•'.repeat(60)}`);
  console.log(`ðŸ’­ Emotional State: ${plan.emotional_state}`);
  console.log(`ðŸ“ˆ Mood: valence=${plan.mood_vector.valence.toFixed(2)}, arousal=${plan.mood_vector.arousal.toFixed(2)}`);
  console.log(`ðŸŽ­ Expression: ${plan.poetic_expression}`);
  console.log(`ðŸŽ¯ Intent: ${plan.intent}`);
  console.log(`${'â”€'.repeat(60)}`);
}

/**
 * Visual Percept Generation Loop
 * Simulates camera percepts arriving continuously
 */
setInterval(() => {
  const percept = generateVisualPercept();
  perceptBuffer.push(percept);
  
  // Only log active percepts (not "NOPE")
  if (percept.action !== "NOPE") {
    console.log(`ðŸ‘ï¸  Visual: ${percept.emoji} ${percept.action}`);
  }
}, VISUAL_PERCEPT_INTERVAL_MS);

/**
 * Audio Percept Generation Loop
 * Simulates microphone percepts arriving less frequently
 */
setInterval(() => {
  const percept = generateAudioPercept();
  perceptBuffer.push(percept);
  
  // Only log meaningful audio (not silence)
  if (percept.transcript) {
    console.log(`ðŸŽ¤ Audio: ${percept.emoji} "${percept.transcript}"`);
  } else if (percept.analysis !== "Silence" && percept.analysis !== "Background ambient sounds only") {
    console.log(`ðŸŽ¤ Audio: ${percept.emoji} ${percept.analysis}`);
  }
}, AUDIO_PERCEPT_INTERVAL_MS);

/**
 * Core Cognitive Loop
 * Runs every 5 seconds - the robot's deliberative "heartbeat"
 */
setInterval(async () => {
  cycleCount++;
  
  // Step 1: Aggregate recent percepts
  const aggregated = aggregatePercepts(perceptBuffer, 5);
  console.log(`\nðŸ“Š Percepts: ${aggregated.visualCount} visual, ${aggregated.audioCount} audio (${aggregated.activeVisualCount} + ${aggregated.activeAudioCount} active)`);
  console.log(`ðŸ“ Summary: ${aggregated.summary}`);
  
  // Step 2: Generate emotional plan via GPT-4o
  try {
    const startTime = Date.now();
    const emotionalPlan = await generateEmotionalPlan(
      aggregated.summary,
      previousEmotionalState
    );
    const latency = Date.now() - startTime;
    
    // Step 3: Display results
    displayEmotionalPlan(emotionalPlan, cycleCount);
    console.log(`â±ï¸  Latency: ${latency}ms`);
    
    // Step 4: Update state for next cycle
    previousEmotionalState = emotionalPlan;
    
  } catch (error) {
    console.error(`\nâŒ Cycle #${cycleCount} failed:`, error.message);
  }
  
  // Step 5: Clean old percepts (keep last 30 seconds)
  const cutoff = Date.now() - 30000;
  const beforeLength = perceptBuffer.length;
  
  while (perceptBuffer.length > 0 && 
         new Date(perceptBuffer[0].timestamp).getTime() < cutoff) {
    perceptBuffer.shift();
  }
  
  if (beforeLength !== perceptBuffer.length) {
    console.log(`ðŸ—‘ï¸  Cleaned ${beforeLength - perceptBuffer.length} old percepts`);
  }
  
}, COGNITIVE_CYCLE_MS);

// Startup message
console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
console.log('â•‘         MVP Cognizer-1: Core Cognitive Loop              â•‘');
console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
console.log('');
console.log('ðŸš€ Cognitive loop started');
console.log(`â° Cycle interval: ${COGNITIVE_CYCLE_MS}ms (${COGNITIVE_CYCLE_MS/1000}s)`);
console.log(`ðŸ‘ï¸  Visual percept interval: ${VISUAL_PERCEPT_INTERVAL_MS}ms`);
console.log(`ðŸŽ¤ Audio percept interval: ${AUDIO_PERCEPT_INTERVAL_MS}ms`);
console.log('');
console.log('Press Ctrl+C to stop');
console.log('');

